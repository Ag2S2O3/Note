# 训练迭代

## 1. 为什么要用 `batch_idx, data in enumerate(data_loader):` ?

for batch_idx, data in enumerate(data_loader):

作用：enumerate(data_loader) 会返回一个元组 (index, batch_data)，其中 index 是当前批次的**索引**，batch_data 是从 data_loader 中获取的实际数据。这样，你可以同时获得批次的索引和批次的数据。

### 优点：

索引信息：你可以在循环中使用 batch_idx 来获取当前批次的索引值，这对于日志记录、调试或者计算每批次的统计信息非常有用。

日志和进度：在训练时，通常需要记录每个批次的训练状态或进度，这时 batch_idx 允许你将这些信息与批次索引相关联。

## 2. 计算损失函数时需要移到CPU上： `loss = loss_f(outputs.cpu(), labels.cpu())  `

有些损失函数或操作可能不支持 GPU，或者计算在 CPU 上进行更合适。在训练过程中，你可能会在 GPU 上进行前向传播和反向传播，但计算损失时，可能需要将张量移到 CPU 以保证兼容性或稳定性。

## 3. 使用 `_` 来忽略一些输出值

例如 `_, predicted = torch.max(outputs.data, 1)` :

torch.max(outputs.data, 1) 返回两个值：

最大值（值为最大预测概率）, 最大值的索引（即预测的类别）

torch.max 函数的返回值是一个包含两个张量的元组，第一个是最大值，第二个是对应的索引。例如：

```python
values, indices = torch.max(outputs.data, 1)
```

values 是每个样本的最大概率值（在分类任务中通常不是我们关注的）。

indices 是每个样本的最大概率对应的类别索引（这是我们感兴趣的预测类别）。

使用 `_` 是 Python 中的一个惯用做法，用来表示你对某个返回值不感兴趣。在这种情况下，你只关心预测的类别（indices），而不关心最大概率值（values）。

## 4. 混淆矩阵

混淆矩阵是一个用于评估分类模型性能的工具，展示了预测标签与真实标签之间的关系。在二分类或多分类问题中，混淆矩阵可以帮助你了解模型在各个类别上的表现。其结构如下：

```css
              Predicted
              A    B
True    A   [TP, FN]
        B   [FP, TN]
```
其中：

* TP（True Positive）：真实标签为A，预测也为A。
* TN（True Negative）：真实标签为B，预测也为B。
* FP（False Positive）：真实标签为B，预测为A。
* FN（False Negative）：真实标签为A，预测为B。


### 示例

假设你有两个类别（类别0和类别1），conf_mat 是一个 2x2 的矩阵，初始化为零。对于每个样本，你将其真实标签和预测标签的对应位置的计数增加1。最后，conf_mat 会包含模型在所有样本上的预测与真实标签之间的统计信息。

### 代码中的混淆矩阵计算示例

假设有以下预测和标签：

预测：[0, 1, 1, 0]

标签：[0, 0, 1, 1]

那么混淆矩阵将会是：

```css
       Predicted
        0   1
True 0  [1, 1]
     1  [1, 1]
```

* 真实标签为0且预测为0的样本有1个（TP）。
* 真实标签为0但预测为1的样本有1个（FN）。
* 真实标签为1但预测为0的样本有1个（FP）。
* 真实标签为1且预测为1的样本有1个（TN）。

使用混淆矩阵，你可以进一步计算准确率、精确率、召回率等指标。

## 5. 对于分割任务的评价指标

IoU 分数：衡量预测区域与实际目标区域的重叠度，值越高越好。

准确率（Accuracy）：计算预测正确的像素占总像素的比例，值越高越好。

## 6. 使用works提升数据读取性能

num_workers是Dataloader的概念，默认值是0. 是告诉DataLoader实例要使用多少个子进程进行数据加载(和CPU有关，和GPU无关)

如果num_worker设为0，意味着每一轮迭代时，dataloader不再有自主加载数据到RAM这一步骤（因为没有worker了），而是在RAM中找batch，找不到时再加载相应的batch。缺点当然是速度慢。

当num_worker不为0时，每轮到dataloader加载数据时，dataloader一次性创建num_worker个worker，并用batch_sampler将指定batch分配给指定worker，worker将它负责的batch加载进RAM。

num_worker设置得大，好处是训batch速度快，因为下一轮迭代的batch很可能在上一轮/上上一轮...迭代时已经加载好了。坏处是内存开销大，也加重了CPU负担（worker加载数据到RAM的进程是CPU复制的嘛）。num_workers的经验设置值是自己电脑/服务器的CPU核心数，如果CPU很强、RAM也很充足，就可以设置得更大些。

num_worker小了的情况，主进程采集完最后一个worker的batch。此时需要回去采集第一个worker产生的第二个batch。如果该worker此时没有采集完，主线程会卡在这里等。（这种情况出现在，num_works数量少或者batchsize 比较小，显卡很快就计算完了，CPU对GPU供不应求。）

## 7. 使用SGD时每次更新都会降低学习率吗?

使用 SGD（随机梯度下降） 时，每次更新并不会自动降低学习率。SGD 默认使用固定的学习率来更新权重，除非手动设置或使用某些学习率调度策略。学习率是否降低取决于你是否应用了某些额外的技术，比如学习率衰减（learning rate decay）或学习率调度器（learning rate scheduler）。

### 如何控制学习率在训练过程中的变化？

为了提高 SGD 的性能，人们通常会使用一些策略来动态调整学习率：

### 学习率衰减（Learning Rate Decay）：

通过在训练过程中逐渐减少学习率，让模型在接近收敛时可以更精细地调整权重，从而更快找到最优解。

### StepLR 调度器：

通过设置一个固定的间隔（步长），每隔一定的训练步数或 epoch，学习率会按比例减小。例如，训练 10 个 epoch 后将学习率降低一半。

### ReduceLROnPlateau 调度器：

当验证集损失不再改善时，可以减少学习率。这种方法通过监控验证集的损失值来决定是否降低学习率，有助于在训练陷入局部最小值时更好地收敛。

### 总结：
SGD 本身不会每次更新都降低学习率。但你可以通过使用学习率调度器（如 StepLR、ExponentialLR 等）或手动设计衰减策略，让学习率在训练过程中逐渐减小，从而提高模型的收敛性和精度。

# 评估指标

## Dice系数

Dice 系数（Dice coefficient）是一种常用于评估二分类问题的指标，尤其在图像分割任务中用来衡量预测结果与真实标签之间的相似性。Dice 系数的公式为：

$$
\text{Jaccard} = \frac{|A \cap B|}{|A \cup B|}
$$

其中：
- \( A \) 是预测的正类区域。
- \( B \) 是真实的正类区域。
- \( |A \cup B| \) 是 \( A \) 和 \( B \) 的并集，表示总的预测区域和真实区域。

```python
# 假设 pred 和 target 是 PyTorch 张量
# pred 是模型输出的 logits，target 是 ground truth (真实标签)

dice_metric = smp.utils.metrics.Dice(threshold=0.5)  # 二值分割任务常用阈值为 0.5

# 计算 Dice 系数
dice_score = dice_metric(pred, target)
print(f"Dice 系数: {dice_score:.4f}")
```
 
## Jaccard系数

Jaccard 系数和 Dice 系数非常相似，都是衡量预测结果与真实标签的重叠程度。

$$
\text{Jaccard} = \frac{|A \cap B|}{|A \cup B|}
$$

其中：
- \( A \) 是预测的正类区域。
- \( B \) 是真实的正类区域。
- \( |A \cup B| \) 是 \( A \) 和 \( B \) 的并集，表示总的预测区域和真实区域。

```python
# 假设 pred 和 target 是 PyTorch 张量
# pred 是模型输出的 logits，target 是 ground truth (真实标签)

# 初始化 Jaccard (IoU) 指标
iou_metric = smp.utils.metrics.IoU(threshold=0.5)  # 阈值设置为0.5

# 计算 Jaccard 系数 (IoU)
jaccard_score = iou_metric(pred, target)
print(f"Jaccard 系数 (IoU): {jaccard_score:.4f}")

```

## Accuracy准确率

用于衡量模型预测的正确性。对于二值分割任务，准确率定义为模型预测正确的像素点占总像素点的比例

$$
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

其中：
- **TP**: 真实为正且预测为正的像素数（True Positive）。
- **TN**: 真实为负且预测为负的像素数（True Negative）。
- **FP**: 真实为负但预测为正的像素数（False Positive）。
- **FN**: 真实为正但预测为负的像素数（False Negative）。

```python

# 假设模型输出的 logits 和真实标签
pred = torch.rand((1, 1, 256, 256))  # 模型输出
target = torch.randint(0, 2, (1, 1, 256, 256))  # ground truth

# 初始化 Accuracy 指标
accuracy_metric = smp.utils.metrics.Accuracy(threshold=0.5)

# 计算 Accuracy
accuracy_score = accuracy_metric(pred, target)
print(f"Accuracy: {accuracy_score:.4f}")
```

## 评价指标总结

### 1. **Dice 系数 (Dice Coefficient)**

- **优点**：
  - 特别适合评估前景（感兴趣目标）的分割性能。
  - 对于前景和背景比例不平衡的数据集，能够更准确地反映模型对前景的表现。
  
- **缺点**：
  - 对背景（负类）像素的表现没有直接考虑，可能对背景的预测情况不敏感。

### 2. **Jaccard 系数 (IoU, Intersection over Union)**

- **优点**：
  - 适合前景和背景不平衡的数据集，能够评估模型对前景的分割精度。
  - 对于模型的误分类部分有较大的惩罚，促使模型在前景分割上更加准确。
  
- **缺点**：
  - 与 Dice 系数类似，也主要关注前景区域，对背景的预测情况没有直接考量。

### 3. **准确率 (Accuracy)**

- **优点**：
  - 简单易懂，适合前景和背景比例比较均衡的情况。
  - 能够快速概览模型在整体上的表现。
  
- **缺点**：
  - 在数据不平衡的情况下，可能会给出高准确率但实际前景预测表现较差。
  - 对于前景和背景比例极不均衡的任务，准确率可能不够敏感。

### 三者关系

| **指标** | **重点** | **适用场景** | **优缺点** |
|:-:|:-:|:-:|:-:|
| **Accuracy**        | 所有像素的预测是否正确               | 前景和背景像素分布均衡时          | 适合均衡数据，易于计算；但在数据不平衡时可能导致高准确率但前景预测表现较差。      |
| **Dice 系数**       | 前景像素的重叠程度                   | 分割任务，前景和背景不平衡时      | 专注于前景，适合不平衡数据，计算简单；但对背景的表现没有直接考量。                  |
| **Jaccard 系数（IoU）** | 前景预测的精确度和召回率的平衡（联合区域） | 分割任务，不平衡数据的前景评估    | 类似于 Dice，专注前景；惩罚机制更强，有助于模型更精准的分割表现。                   |

