# SLAM

> Simultaneous Localization and Mapping，即时定位与地图构建

## 视觉slam关键技术

*(from chatGPT)*

#### 1. **前端（Front-end）**

主要负责从传感器（如单目、双目、RGB-D相机）中提取信息，计算相邻帧之间的相对位姿。

- **特征提取与匹配**：

  - 常见特征点：ORB、SIFT、SURF、FAST、BRIEF
  - 匹配方法：暴力匹配、FLANN、KNN+RANSAC去除外点

- **运动估计**（视觉里程计 VO）：

  - 基于特征法：PnP（单目）、三角化（双目）
  - 基于直接法（Direct Method）：直接使用像素灰度优化位姿
  - 基于光流法（Optical Flow）：稀疏光流或稠密光流


#### 2. **后端优化（Back-end / Local Bundle Adjustment）**

优化来自前端的轨迹，提升整体精度和一致性。

- **非线性优化框架**：g2o、Ceres Solver
- **位姿图优化**：构建图模型（节点为位姿，边为相对变换），通过 BA 进行全局优化

#### 3. **闭环检测（Loop Closure Detection）**

检测系统是否回到过曾经到过的位置，修正累积误差。

- **图像重识别方法**：

  - Bag of Words（BoW）：DBoW2、FAB-MAP
  - 深度学习方法：NetVLAD、DeepLoop、SuperGlue

- **闭环约束构建与图优化**：新约束加入位姿图中，并进行全局优化

#### 4. **地图构建（Mapping）**

构建稠密或稀疏地图。

- **稀疏地图**：由特征点组成
- **稠密地图**：通过立体匹配或深度估计得到
- **语义地图**（拓展方向）：结合目标识别，加入语义标签（物体、房间等）

#### 5. **初始化与重定位**

- **初始化**：

  - 单目需要进行初始化（静态场景+足够视差）
  - 双目/RGB-D可以直接估深度

- **重定位**：

  - 系统失效后重新定位
  - 利用全局图像匹配 + PnP 恢复位姿


#### 6. **尺度恢复与尺度漂移（单目特有问题）**

- 单目视觉无法直接获得尺度信息，需借助其他手段恢复尺度，如：

  - 使用 IMU（VIO）
  - 使用物体尺寸先验
  - 使用多视图三角化推测尺度


#### 7. **传感器融合**

提升鲁棒性与精度：

- **IMU+Camera（VIO）**：视觉惯性里程计（如VINS-Fusion）
- **LiDAR+Camera**：异构传感器融合（如LVI-SAM）

## SLAM融合深度学习

### 1.  语义SLAM（Semantic SLAM）

#### 核心思想

在传统SLAM中加入**语义信息（如“墙”、“人”、“桌子”等物体标签）**，让地图不仅仅是几何结构，还具备“理解力”。

#### 优势

- 增强地图表达力（几何 + 语义）
- 支持语义级定位与导航（如“导航到办公桌”）
- 有助于动态物体的剔除（如行人、车辆）
- 实现**人类级感知与交互**

#### 关键技术模块

- **语义分割 / 目标检测**（深度学习）：

  - 网络：DeepLabv3+, Mask R-CNN, YOLOv8-Seg, Segment Anything（SAM）等
  - 输出每个像素或物体的语义标签

- **语义地图构建**：

  - 给地图中点/区域打上语义标签
  - 可能构建：稀疏语义地图、稠密语义地图、OctoMap等

- **语义数据关联**：

  - 跟踪相同语义实体（如“桌子A”）跨帧一致性

- **动态物体处理**：

  - 利用语义剔除动态目标对SLAM的干扰（如人、车）


### 2.  深度SLAM（Deep SLAM）

#### 核心思想

用**深度神经网络替代/增强传统SLAM中的部分模块**，例如深度估计、位姿估计、特征提取、地图构建等。